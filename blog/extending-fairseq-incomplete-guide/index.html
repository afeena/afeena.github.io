<!DOCTYPE html>

<html lang="en-us"><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha256-4+XzXVhsDmqanXGHaHvgh1gMQKX40OUvDEBTu8JcmNs=" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css"
        integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Nanum+Myeongjo&family=Noto+Serif+JP&family=Cormorant+Garamond&family=Libre+Baskerville&family=Source+Serif+Pro&family=Crimson+Text&family=Inter&family=Crimson+Pro&family=Literata&family=Ubuntu+Mono&family=Inter&family=Roboto">
    <link rel="stylesheet" type="text/css" href="/css/style.css">

    
    

    <title>Evgeniia Tokarchuk | Extending Fairseq: Incomplete Guide</title>


    

</head><body class="container d-flex flex-column min-vh-100">

<div class="blog_nav_bar secondary_font ">
    
    
    <a class="navbar-brand" href="/">about</a>
    
    
    
    <a class="navbar-brand" href="/blog">« all posts</a>
    
    
</div>



<h3>
    <a class="title" href="/blog/extending-fairseq-incomplete-guide/">Extending Fairseq: Incomplete Guide</a>
</h3>

<div class="reading_time secondary_font text-muted ">
    <span>
        Oct 17 2022 · 4 min read
    </span>

</div>




<div class="tags_navigation">
    
    <a class="tag" href="/tags/fairseq/">#fairseq</a>
    
    <a class="tag" href="/tags/nlp/">#nlp</a>
    
    <a class="tag" href="/tags/machine-learning/">#machine-learning</a>
    
</div>


<h2 id="table-of-content">Table of content</h2>
<ol start="0">
<li><a href="#fairseq-how-to">Fairseq How To</a></li>
<li><a href="extension-easy-mode">Easy Mode</a></li>
<li><a href="extension-not-so-easy-mode">Not So Easy Mode</a></li>
</ol>
<h2 id="fairseq-how-to">Fairseq How To</h2>
<p>Before we start with extension, let&rsquo;s try to understand how <code>fairseq</code> training works for <code>seq2seq</code> models. In this tutorial I will use only <code>hydra-train</code> module to make it possible load <code>yaml</code> configs.</p>
<h3 id="install-fairseq">Install fairseq</h3>
<p>Follow <a href="https://github.com/facebookresearch/fairseq/">installation guide</a> on github page.</p>
<h3 id="training-with-hydra">Training with Hydra</h3>
<p>Suppose you want to train <code>translation</code> model using hydra training. The command syntax is the following:</p>
<pre tabindex="0"><code class="language-bash!" data-lang="bash!">uname@host ~ $ fairseq-hydra-train --config-dir . --config-name config.yaml
</code></pre><p>Obviously you need to prepare <code>config.yaml</code> first. All missing parameters will be reaplced by defaults. Defaults can be find at <code>fairseq/dataclass/configs.py</code>
You can also see avaliable parameters there.</p>
<details>
    <summary> <b>Translation Config Example </b></summary>
<pre tabindex="0"><code class="language-yaml!" data-lang="yaml!"># @package _group_
task:
  _name: translation
  data: fairseq-bin-data
  source_lang: ro
  target_lang: en
  eval_bleu: true
  eval_bleu_args: &#39;{&#34;beam&#34;:1}&#39;
  eval_bleu_detok: &#34;moses&#34;
  eval_bleu_remove_bpe: subword_nmt
  eval_bleu_print_samples: false
criterion:
  _name: cross-entropy
model:
  _name: transformer_base
  decoder:
    output_dim: 100
    learned_pos: true
  encoder:
    learned_pos: true
  dropout: 0.3
optimizer:
  _name: adam
  adam_betas: (0.9,0.98)
lr_scheduler:
  _name: inverse_sqrt
  warmup_updates: 10000
  warmup_init_lr: 1e-07
dataset:
  max_tokens: 4000
  validate_interval_updates: 2000
optimization:
  lr: [0.0005]
  update_freq: [16]
  max_update: 50000
  stop_min_lr: 1e-09
checkpoint:
  best_checkpoint_metric: bleu
  maximize_best_checkpoint_metric: true
common:
  wandb_project: ?
  log_format: simple
  log_interval: 100
</code></pre></details>
<p>You can replace or add parameters <strong>on the fly</strong> while keeping base config. If parameter not in a base config, use <code>+</code> to add it:</p>
<pre tabindex="0"><code class="language-bash!" data-lang="bash!">#checkpoint.no_save is not in config.yaml so add +
#common.wandb_project is in base config, so no need to add +
uname@host ~ $ fairseq-hydra-train --config-dir . --config-name config.yaml common.wandb_project=myproject +checkpoint.no_save=True
</code></pre><h3 id="fairseq-training-flow">Fairseq Training Flow</h3>
<p>Look at the diagram to see what happens when you call training! (<strong>warining</strong>: it&rsquo;s huge).</p>
<p><a href="https://drive.google.com/file/d/1cWoPvC88oop3P6l3NQb7-e4dkBYRlc3p/view?usp=sharing">Fairseq Training Flow</a></p>
<hr>
<h2 id="extension-easy-mode">Extension Easy Mode</h2>
<p>The <em><strong>easiest</strong></em> way to extend <code>fairseq</code> is to fork <code>fairseq</code> repository and add your files (model/criterion/task etc).</p>
<pre tabindex="0"><code class="language-python!" data-lang="python!">@register_task(name, dataclass=TaskConfigClass)
@register_model(name, dataclass=ModelConfigClass)
@register_criterion(name, dataclass=CriterionConfigClass)
</code></pre><h3 id="add-new-model">Add new model</h3>
<ol>
<li>Add file under the <code>fairseq/model/</code> folder. E.g., we create a <code>fairseq/model/my_new_fancy_model.py</code></li>
<li>Open your file in editor and add model code! Let&rsquo;s assume you extend <code>transformer_base</code></li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#dataclass defines all additional params for the model</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@dataclass</span> 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyNewFancyModelConfig</span>(TransformerConfig):
</span></span><span style="display:flex;"><span>    new_param: Optional[str] <span style="color:#f92672">=</span> field(
</span></span><span style="display:flex;"><span>        default<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>        metadata<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#34;help&#34;</span>: <span style="color:#e6db74">&#34;It will be needed in my model&#34;</span>},
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#75715e">#very important! don&#39;t forget to register your model with unique name</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@register_model</span>(<span style="color:#e6db74">&#34;fancy_model&#34;</span>, dataclass<span style="color:#f92672">=</span>ContinuousTransformerConfig) 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyNewFancyModel</span>(TransformerModelBase):
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(sels, cfg, encoder, decoder):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__(encoder, decoder)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>cfg <span style="color:#f92672">=</span> cfg
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#now you can access the params from config</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#e.g. you want to access new_param from MyNewFancyModelConfig</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#self.cfg.new_param viola!</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">@classmethod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_decoder</span>(cls, cfg, tgt_dict, embed_tokens):
</span></span><span style="display:flex;"><span>        decoder <span style="color:#f92672">=</span> MyNewFancyDecoderBecauseIcan(
</span></span><span style="display:flex;"><span>            cfg,
</span></span><span style="display:flex;"><span>            tgt_dict,
</span></span><span style="display:flex;"><span>            embed_tokens,
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> decoder
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(
</span></span><span style="display:flex;"><span>            self,
</span></span><span style="display:flex;"><span>            src_tokens,
</span></span><span style="display:flex;"><span>            src_lengths,
</span></span><span style="display:flex;"><span>            prev_output_tokens,
</span></span><span style="display:flex;"><span>            return_all_hiddens: bool <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>            features_only: bool <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>            alignment_layer: Optional[int] <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>            alignment_heads: Optional[int] <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>    ):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#all magic of your model happens here</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>        
</span></span></code></pre></div><ol start="3">
<li>Call new model by passing <code>model._name=fancy_model</code></li>
</ol>
<h3 id="add-new-criterion">Add new criterion</h3>
<p>Similarly to the model, you can create new criterion under <code>fairseq/criterions</code></p>
<ol>
<li>Create your criterion file</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> dataclasses <span style="color:#f92672">import</span> dataclass
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> fairseq.criterions <span style="color:#f92672">import</span> FairseqCriterion, register_criterion
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> fairseq.dataclass <span style="color:#f92672">import</span> FairseqDataclass
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@dataclass</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyNewCriterionConfig</span>(FairseqDataclass):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">pass</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@register_criterion</span>(<span style="color:#e6db74">&#34;my_new_criterion&#34;</span>, dataclass<span style="color:#f92672">=</span>MyNewCriterionConfig)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MyNewCriterion</span>(FairseqCriterion):
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, model, sample, reduce<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#loss calculation happens here</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#loss, sample_size, logging_output = f()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> loss, sample_size, logging_output
</span></span></code></pre></div><ol start="2">
<li>Implement loss calculation</li>
<li>Run model with <code>criterion._name=my_new_criterion</code></li>
</ol>
<h3 id="notes">Notes</h3>
<ol>
<li>You can add tasks and so on in the similar manner.</li>
<li>Do not forget to also import your new model/criterion in the <code>__init__</code> file of the respective module</li>
</ol>
<hr>
<h2 id="extension-not-so-easy-mode">Extension Not So Easy Mode</h2>
<p>So you decided to create your own lib built on top of <code>fairseq</code>. Good luck (/jk). There are several reasons you might want to do it, e.g.</p>
<ul>
<li>It&rsquo;s easier to maintain</li>
<li>It clearly separates your code</li>
</ul>
<p>To make your own lib on top of<code>fairseq</code> you need mainly replace <code>fairseq</code> imports with your own imports. That might require <em>&ldquo;monkeypatching&rdquo;</em>.</p>
<p>Example of patched <code>hydra-train</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">First import main hydra-train module from fairseq.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">And all modules needed from your own lib
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> fairseq_cli.hydra_train <span style="color:#66d9ef">as</span> fairseq_hydra_train 
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> cdgm_textgen.dataclass.utils <span style="color:#f92672">import</span> omegaconf_no_object_check <span style="color:#66d9ef">as</span> cdgm_omegaconf_no_object_check
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> cdgm_textgen.dataclass.configs <span style="color:#f92672">import</span> CDGMTextgenConfig
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> cdgm_textgen.dataclass.initialize <span style="color:#f92672">import</span> add_defaults <span style="color:#66d9ef">as</span> cdgm_add_defaults
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> cdgm_textgen.dataclass.initialize <span style="color:#f92672">import</span> hydra_init <span style="color:#66d9ef">as</span> cdgm_hydra_init
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> cdgm_textgen_cli.train <span style="color:#f92672">import</span> main <span style="color:#66d9ef">as</span> cdgm_pre_main
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;replacing&#34; functions/modules of hydra_train
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>fairseq_hydra_train<span style="color:#f92672">.</span>omegaconf_no_object_check <span style="color:#f92672">=</span> cdgm_omegaconf_no_object_check
</span></span><span style="display:flex;"><span>fairseq_hydra_train<span style="color:#f92672">.</span>FairseqConfig <span style="color:#f92672">=</span> CDGMTextgenConfig
</span></span><span style="display:flex;"><span>fairseq_hydra_train<span style="color:#f92672">.</span>add_defaults <span style="color:#f92672">=</span> cdgm_add_defaults
</span></span><span style="display:flex;"><span>fairseq_hydra_train<span style="color:#f92672">.</span>hydra_init <span style="color:#f92672">=</span> cdgm_hydra_init
</span></span><span style="display:flex;"><span>fairseq_hydra_train<span style="color:#f92672">.</span>pre_main <span style="color:#f92672">=</span> cdgm_pre_main
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#call original functions</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">cli_main</span>():
</span></span><span style="display:flex;"><span>    fairseq_hydra_train<span style="color:#f92672">.</span>cli_main()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    fairseq_hydra_train<span style="color:#f92672">.</span>cli_main()
</span></span></code></pre></div><ul>
<li>You need to patch <strong>each</strong> module you modifying (be aware of imports)</li>
<li>Import <code>fairseq</code> modules when needed. E.g., new criterion with cosine similarity is inhereted from <code>CrossEntropyCriterion</code> from fairseq</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> math
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> dataclasses <span style="color:#f92672">import</span> field
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> typing <span style="color:#f92672">import</span> Optional
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.distributions <span style="color:#f92672">import</span> multivariate_normal
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> dataclasses <span style="color:#f92672">import</span> dataclass
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> fairseq <span style="color:#f92672">import</span> metrics, utils
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> fairseq.criterions <span style="color:#f92672">import</span> register_criterion, FairseqCriterion
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> fairseq.criterions.cross_entropy <span style="color:#f92672">import</span> CrossEntropyCriterion, CrossEntropyCriterionConfig
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> power_spherical
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> fairseq.dataclass <span style="color:#f92672">import</span> FairseqDataclass
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@register_criterion</span>(<span style="color:#e6db74">&#34;cosine_ar_criterion&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CosineARCriterion</span>(CrossEntropyCriterion):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, model, sample, reduce<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">pass</span>
</span></span></code></pre></div><ul>
<li><strong>Worst case scenario</strong>: Sometime is it hard to disentangle code, so you need to copy files from original repository (code duplication).</li>
<li>After patching <em>basic</em> functions you can create your new models/criterions/tasks similar as in <a href="#extension-easy-mode">previous section</a></li>
</ul>


<footer class="mt-auto d-flex justify-content-center text-muted small secondary_font">
    <span class="text-muted">Copyright (c) 2022, E Tokarchuk,
        <a class="text-muted" href="https://github.com/hadisinaee/avicenna" target="_blank"> created by Avicenna
            (MIT)</a>
    </span>
</footer><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx"
    crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/feather-icons/4.28.0/feather.min.js"></script>
<script>
    feather.replace()
</script></body>

</html>